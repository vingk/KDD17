--------------------------------------------------
Step 1: Load data
--------------------------------------------------
CSV Type: <class 'pandas.core.frame.DataFrame'>, Shape: (5914, 96)
  Number of irrelevant advisories  : 553
  Number of orphaned advisories (O): 20
  Number of started advisories  (S): 533
  Total number of advisories  (O+S): 553
  Number of cancellations       (C): 441
  Number of extensions          (E): 137
  Number of reductions          (R): 124
  Number of amendments          (A): 295
  Total number of changes (C+E+R+A): 997
  Number of unchangeds          (U): 3811
  Total number of hours (C+E+R+A+U): 4808
--------------------------------------------------
Step 2: Group into train and test sets by year
--------------------------------------------------
Year 2010
  Number of {C, E, R, A, U} samples: 97, 39, 17, 87, 922
  Total number of samples:           1162
Year 2011
  Number of {C, E, R, A, U} samples: 92, 23, 30, 67, 853
  Total number of samples:           1065
Year 2012
  Number of {C, E, R, A, U} samples: 111, 27, 37, 46, 858
  Total number of samples:           1079
Year 2013
  Number of {C, E, R, A, U} samples: 103, 31, 30, 71, 825
  Total number of samples:           1060
Year 2014
  Number of {C, E, R, A, U} samples: 38, 17, 10, 24, 353
  Total number of samples:           442
Train and test sets for year 2011
  Number of {C, E, R, A, U} train samples: 97, 39, 17, 87, 922
  Total number of train samples:           1162
  Number of {C, E, R, A, U} test samples:  92, 23, 30, 67, 853
  Total number of test samples:            1065
Train and test sets for year 2011 (merged into 3 classes)
  Number of {+, -, 0} train samples: 39, 114, 1009
  Total number of train samples:     1162
  Number of {+, -, 0} test samples:  23, 122, 920
  Total number of test samples:      1065
Train and test sets for year 2012
  Number of {C, E, R, A, U} train samples: 189, 62, 47, 154, 1775
  Total number of train samples:           2227
  Number of {C, E, R, A, U} test samples:  111, 27, 37, 46, 858
  Total number of test samples:            1079
Train and test sets for year 2012 (merged into 3 classes)
  Number of {+, -, 0} train samples: 62, 236, 1929
  Total number of train samples:     2227
  Number of {+, -, 0} test samples:  27, 148, 904
  Total number of test samples:      1079
Train and test sets for year 2013
  Number of {C, E, R, A, U} train samples: 300, 89, 84, 200, 2633
  Total number of train samples:           3306
  Number of {C, E, R, A, U} test samples:  103, 31, 30, 71, 825
  Total number of test samples:            1060
Train and test sets for year 2013 (merged into 3 classes)
  Number of {+, -, 0} train samples: 89, 384, 2833
  Total number of train samples:     3306
  Number of {+, -, 0} test samples:  31, 133, 896
  Total number of test samples:      1060
Train and test sets for year 2014
  Number of {C, E, R, A, U} train samples: 403, 120, 114, 271, 3458
  Total number of train samples:           4366
  Number of {C, E, R, A, U} test samples:  38, 17, 10, 24, 353
  Total number of test samples:            442
Train and test sets for year 2014 (merged into 3 classes)
  Number of {+, -, 0} train samples: 120, 517, 3729
  Total number of train samples:     4366
  Number of {+, -, 0} test samples:  17, 48, 377
  Total number of test samples:      442
--------------------------------------------------
Step 3: Calculate train and test sets indices
--------------------------------------------------
Number of samples in Xtrainall: 4808
Number of samples in ytrainall: 4808
  Number of samples in trainindiceslist[0]: 1162
  Number of samples in testindiceslist [0]: 1065
  Number of samples in trainindiceslist[1]: 2227
  Number of samples in testindiceslist [1]: 1079
  Number of samples in trainindiceslist[2]: 3306
  Number of samples in testindiceslist [2]: 1060
  Number of samples in trainindiceslist[3]: 4366
  Number of samples in testindiceslist [3]: 442
--------------------------------------------------
Step 4: Run Naive Bayes
--------------------------------------------------
Running Naive Bayes on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.795305164319
  Macro recall    : 0.451003801378
  Macro precision : 0.45707387828
  Macro F1 score  : 0.431202650297
  Confusion matrix:
[[  5   4  14]
 [ 19  31  72]
 [ 69  40 811]]
Running Naive Bayes on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.796107506951
  Macro recall    : 0.461383581221
  Macro precision : 0.49122102022
  Macro F1 score  : 0.455419111598
  Confusion matrix:
[[  5   5  17]
 [ 23  45  80]
 [ 59  36 809]]
Running Naive Bayes on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.77358490566
  Macro recall    : 0.477742996604
  Macro precision : 0.458852287853
  Macro F1 score  : 0.452330239038
  Confusion matrix:
[[  8   5  18]
 [ 18  42  73]
 [ 67  59 770]]
Running Naive Bayes on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.776018099548
  Macro recall    : 0.531844324821
  Macro precision : 0.474656084656
  Macro F1 score  : 0.471511359595
  Confusion matrix:
[[  8   2   7]
 [ 14  13  21]
 [ 34  21 322]]
--------------------------------------------------
Step 5: Find Best Parameters for Decision Tree Classifier using Grid Search
--------------------------------------------------
Running Grid Search on Decision Tree Classifier on classes ('+', '-', '0')
  Best parameters         : {'min_impurity_decrease': 0.003, 'max_leaf_nodes': 10, 'min_samples_leaf': 0.04, 'min_samples_split': 0.12, 'min_weight_fraction_leaf': 0.0, 'random_state': 1520464997, 'max_features': 2, 'max_depth': 3, 'class_weight': 'balanced'}
  Best score              : 0.482887986876
  Best feature importances: [ 0.          0.          0.21952946  0.27300333  0.23048859  0.27697862]
--------------------------------------------------
Step 6: Run Decision Tree Classifier using Best Parameters
--------------------------------------------------
Running Decision Tree Classifier on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.757746478873
  Macro recall    : 0.57387740556
  Macro precision : 0.460615668439
  Macro F1 score  : 0.481329241344
  Confusion matrix:
[[  6  10   7]
 [ 11  83  28]
 [ 50 152 718]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.745539906103
  Macro recall    : 0.592599192207
  Macro precision : 0.467334311914
  Macro F1 score  : 0.480481714753
  Confusion matrix:
[[  9   9   5]
 [ 21  75  26]
 [ 91 119 710]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.753990610329
  Macro recall    : 0.57716797339
  Macro precision : 0.460387608838
  Macro F1 score  : 0.48018184657
  Confusion matrix:
[[  6  12   5]
 [ 11  85  26]
 [ 50 158 712]]
Running Decision Tree Classifier on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.753475440222
  Macro recall    : 0.570085941399
  Macro precision : 0.474898154805
  Macro F1 score  : 0.495012804206
  Confusion matrix:
[[  7  13   7]
 [ 14  99  35]
 [ 49 148 707]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.739573679333
  Macro recall    : 0.547747231007
  Macro precision : 0.46679558314
  Macro F1 score  : 0.472646162794
  Confusion matrix:
[[ 10   9   8]
 [ 30  71  47]
 [ 86 101 717]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.753475440222
  Macro recall    : 0.570085941399
  Macro precision : 0.474898154805
  Macro F1 score  : 0.495012804206
  Confusion matrix:
[[  7  13   7]
 [ 14  99  35]
 [ 49 148 707]]
Running Decision Tree Classifier on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.730188679245
  Macro recall    : 0.545999575552
  Macro precision : 0.455374930927
  Macro F1 score  : 0.472935653717
  Confusion matrix:
[[  8  14   9]
 [ 10  82  41]
 [ 53 159 684]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.708490566038
  Macro recall    : 0.564998054612
  Macro precision : 0.4502962139
  Macro F1 score  : 0.455874986446
  Confusion matrix:
[[ 16  10   5]
 [ 36  56  41]
 [103 114 679]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.71320754717
  Macro recall    : 0.546096844935
  Macro precision : 0.445788975498
  Macro F1 score  : 0.452635783977
  Confusion matrix:
[[ 14  12   5]
 [ 32  56  45]
 [ 95 115 686]]
Running Decision Tree Classifier on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.737556561086
  Macro recall    : 0.564752691528
  Macro precision : 0.467749296781
  Macro F1 score  : 0.480912555297
  Confusion matrix:
[[  7   8   2]
 [ 10  24  14]
 [ 43  39 295]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.730769230769
  Macro recall    : 0.638080563791
  Macro precision : 0.503209794664
  Macro F1 score  : 0.494090244794
  Confusion matrix:
[[ 13   3   1]
 [ 20  18  10]
 [ 62  23 292]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.744343891403
  Macro recall    : 0.560259227475
  Macro precision : 0.464497843618
  Macro F1 score  : 0.48421453654
  Confusion matrix:
[[  5  10   2]
 [  5  29  14]
 [ 25  57 295]]
--------------------------------------------------
Step 7: Calculate f-statistic
--------------------------------------------------
Calculating f-statistic for Decision Tree Classifier (No resampling vs SMOTE oversampling vs TOMEK undersampling)
  F-statistic: 0.215349328377, P-Value: 0.810296358257
--------------------------------------------------
Step 8: Calculate t-statistic
--------------------------------------------------
Calculating t-statistic for Naive Bayes and Decision Tree Classifier (No resampling)
  T-statistic: -3.16177161945, P-Value: 0.0274548871441
--------------------------------------------------
Step 9: Fit Decision Tree to Whole Dataset and Export to File
--------------------------------------------------
Running Decision Tree Classifier on whole dataset
  Decision Tree Exported to File:gdp_tree_2017-12-21_23-35-37.png
