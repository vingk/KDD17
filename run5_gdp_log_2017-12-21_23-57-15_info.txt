--------------------------------------------------
Step 1: Load data
--------------------------------------------------
CSV Type: <class 'pandas.core.frame.DataFrame'>, Shape: (5914, 96)
  Number of irrelevant advisories  : 553
  Number of orphaned advisories (O): 20
  Number of started advisories  (S): 533
  Total number of advisories  (O+S): 553
  Number of cancellations       (C): 441
  Number of extensions          (E): 137
  Number of reductions          (R): 124
  Number of amendments          (A): 295
  Total number of changes (C+E+R+A): 997
  Number of unchangeds          (U): 3811
  Total number of hours (C+E+R+A+U): 4808
--------------------------------------------------
Step 2: Group into train and test sets by year
--------------------------------------------------
Year 2010
  Number of {C, E, R, A, U} samples: 97, 39, 17, 87, 922
  Total number of samples:           1162
Year 2011
  Number of {C, E, R, A, U} samples: 92, 23, 30, 67, 853
  Total number of samples:           1065
Year 2012
  Number of {C, E, R, A, U} samples: 111, 27, 37, 46, 858
  Total number of samples:           1079
Year 2013
  Number of {C, E, R, A, U} samples: 103, 31, 30, 71, 825
  Total number of samples:           1060
Year 2014
  Number of {C, E, R, A, U} samples: 38, 17, 10, 24, 353
  Total number of samples:           442
Train and test sets for year 2011
  Number of {C, E, R, A, U} train samples: 97, 39, 17, 87, 922
  Total number of train samples:           1162
  Number of {C, E, R, A, U} test samples:  92, 23, 30, 67, 853
  Total number of test samples:            1065
Train and test sets for year 2011 (merged into 3 classes)
  Number of {+, -, 0} train samples: 39, 114, 1009
  Total number of train samples:     1162
  Number of {+, -, 0} test samples:  23, 122, 920
  Total number of test samples:      1065
Train and test sets for year 2012
  Number of {C, E, R, A, U} train samples: 189, 62, 47, 154, 1775
  Total number of train samples:           2227
  Number of {C, E, R, A, U} test samples:  111, 27, 37, 46, 858
  Total number of test samples:            1079
Train and test sets for year 2012 (merged into 3 classes)
  Number of {+, -, 0} train samples: 62, 236, 1929
  Total number of train samples:     2227
  Number of {+, -, 0} test samples:  27, 148, 904
  Total number of test samples:      1079
Train and test sets for year 2013
  Number of {C, E, R, A, U} train samples: 300, 89, 84, 200, 2633
  Total number of train samples:           3306
  Number of {C, E, R, A, U} test samples:  103, 31, 30, 71, 825
  Total number of test samples:            1060
Train and test sets for year 2013 (merged into 3 classes)
  Number of {+, -, 0} train samples: 89, 384, 2833
  Total number of train samples:     3306
  Number of {+, -, 0} test samples:  31, 133, 896
  Total number of test samples:      1060
Train and test sets for year 2014
  Number of {C, E, R, A, U} train samples: 403, 120, 114, 271, 3458
  Total number of train samples:           4366
  Number of {C, E, R, A, U} test samples:  38, 17, 10, 24, 353
  Total number of test samples:            442
Train and test sets for year 2014 (merged into 3 classes)
  Number of {+, -, 0} train samples: 120, 517, 3729
  Total number of train samples:     4366
  Number of {+, -, 0} test samples:  17, 48, 377
  Total number of test samples:      442
--------------------------------------------------
Step 3: Calculate train and test sets indices
--------------------------------------------------
Number of samples in Xtrainall: 4808
Number of samples in ytrainall: 4808
  Number of samples in trainindiceslist[0]: 1162
  Number of samples in testindiceslist [0]: 1065
  Number of samples in trainindiceslist[1]: 2227
  Number of samples in testindiceslist [1]: 1079
  Number of samples in trainindiceslist[2]: 3306
  Number of samples in testindiceslist [2]: 1060
  Number of samples in trainindiceslist[3]: 4366
  Number of samples in testindiceslist [3]: 442
--------------------------------------------------
Step 4: Run Naive Bayes
--------------------------------------------------
Running Naive Bayes on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.795305164319
  Macro recall    : 0.451003801378
  Macro precision : 0.45707387828
  Macro F1 score  : 0.431202650297
  Confusion matrix:
[[  5   4  14]
 [ 19  31  72]
 [ 69  40 811]]
Running Naive Bayes on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.796107506951
  Macro recall    : 0.461383581221
  Macro precision : 0.49122102022
  Macro F1 score  : 0.455419111598
  Confusion matrix:
[[  5   5  17]
 [ 23  45  80]
 [ 59  36 809]]
Running Naive Bayes on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.77358490566
  Macro recall    : 0.477742996604
  Macro precision : 0.458852287853
  Macro F1 score  : 0.452330239038
  Confusion matrix:
[[  8   5  18]
 [ 18  42  73]
 [ 67  59 770]]
Running Naive Bayes on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.776018099548
  Macro recall    : 0.531844324821
  Macro precision : 0.474656084656
  Macro F1 score  : 0.471511359595
  Confusion matrix:
[[  8   2   7]
 [ 14  13  21]
 [ 34  21 322]]
--------------------------------------------------
Step 5: Find Best Parameters for Decision Tree Classifier using Grid Search
--------------------------------------------------
Running Grid Search on Decision Tree Classifier on classes ('+', '-', '0')
  Best parameters         : {'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 10, 'min_samples_leaf': 0.02, 'min_samples_split': 0.04, 'min_weight_fraction_leaf': 0.0, 'random_state': 390324480, 'max_features': 5, 'max_depth': 2, 'class_weight': 'balanced'}
  Best score              : 0.48422521263
  Best feature importances: [ 0.          0.          0.04807982  0.7022253   0.2327392   0.01695568]
--------------------------------------------------
Step 6: Run Decision Tree Classifier using Best Parameters
--------------------------------------------------
Running Decision Tree Classifier on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.77558685446
  Macro recall    : 0.613673081492
  Macro precision : 0.47978376173
  Macro F1 score  : 0.507323806488
  Confusion matrix:
[[  9   8   6]
 [ 13  79  30]
 [ 54 128 738]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.750234741784
  Macro recall    : 0.5969588976
  Macro precision : 0.465938940109
  Macro F1 score  : 0.486503150984
  Confusion matrix:
[[  7  11   5]
 [ 15  88  19]
 [ 44 172 704]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.772769953052
  Macro recall    : 0.621887621763
  Macro precision : 0.484181452721
  Macro F1 score  : 0.504017566997
  Confusion matrix:
[[ 11   6   6]
 [ 21  71  30]
 [ 78 101 741]]
Running Decision Tree Classifier on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.752548656163
  Macro recall    : 0.576719418534
  Macro precision : 0.476157726612
  Macro F1 score  : 0.494900084098
  Confusion matrix:
[[  9  11   7]
 [ 23  90  35]
 [ 57 134 713]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.775718257646
  Macro recall    : 0.560632166089
  Macro precision : 0.487286158339
  Macro F1 score  : 0.506671472815
  Confusion matrix:
[[  5  14   8]
 [  7 102  39]
 [ 24 150 730]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.734012974977
  Macro recall    : 0.582141507289
  Macro precision : 0.481456953642
  Macro F1 score  : 0.476925090233
  Confusion matrix:
[[ 14   6   7]
 [ 48  65  35]
 [106  85 713]]
Running Decision Tree Classifier on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.724528301887
  Macro recall    : 0.524559256003
  Macro precision : 0.447630706089
  Macro F1 score  : 0.456607457112
  Confusion matrix:
[[  8  16   7]
 [ 26  73  34]
 [ 73 136 687]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.742452830189
  Macro recall    : 0.467500025265
  Macro precision : 0.417574690012
  Macro F1 score  : 0.425853296973
  Confusion matrix:
[[  1  21   9]
 [  9  77  47]
 [ 28 159 709]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.697169811321
  Macro recall    : 0.51998317366
  Macro precision : 0.433906709839
  Macro F1 score  : 0.420894470036
  Confusion matrix:
[[ 16  10   5]
 [ 58  37  38]
 [125  85 686]]
Running Decision Tree Classifier on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.730769230769
  Macro recall    : 0.556582756887
  Macro precision : 0.459741647242
  Macro F1 score  : 0.468742479768
  Confusion matrix:
[[  8   4   5]
 [ 16  20  12]
 [ 42  40 295]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.730769230769
  Macro recall    : 0.56924615558
  Macro precision : 0.483700750469
  Macro F1 score  : 0.477988337658
  Confusion matrix:
[[  9   3   5]
 [ 17  19  12]
 [ 56  26 295]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.712669683258
  Macro recall    : 0.556655354449
  Macro precision : 0.471075229056
  Macro F1 score  : 0.454114881534
  Confusion matrix:
[[ 10   3   4]
 [ 22  15  11]
 [ 63  24 290]]
--------------------------------------------------
Step 7: Calculate f-statistic
--------------------------------------------------
Calculating f-statistic for Decision Tree Classifier (No resampling vs SMOTE oversampling vs TOMEK undersampling)
  F-statistic: 0.326167581451, P-Value: 0.729870012764
--------------------------------------------------
Step 8: Calculate t-statistic
--------------------------------------------------
Calculating t-statistic for Naive Bayes and Decision Tree Classifier (No resampling)
  T-statistic: -2.0482915396, P-Value: 0.091513374505
--------------------------------------------------
Step 9: Fit Decision Tree to Whole Dataset and Export to File
--------------------------------------------------
Running Decision Tree Classifier on whole dataset
  Decision Tree Exported to File:gdp_tree_2017-12-21_23-57-15.png
