--------------------------------------------------
Step 1: Load data
--------------------------------------------------
CSV Type: <class 'pandas.core.frame.DataFrame'>, Shape: (5914, 96)
  Number of irrelevant advisories  : 553
  Number of orphaned advisories (O): 20
  Number of started advisories  (S): 533
  Total number of advisories  (O+S): 553
  Number of cancellations       (C): 441
  Number of extensions          (E): 137
  Number of reductions          (R): 124
  Number of amendments          (A): 295
  Total number of changes (C+E+R+A): 997
  Number of unchangeds          (U): 3811
  Total number of hours (C+E+R+A+U): 4808
--------------------------------------------------
Step 2: Group into train and test sets by year
--------------------------------------------------
Year 2010
  Number of {C, E, R, A, U} samples: 97, 39, 17, 87, 922
  Total number of samples:           1162
Year 2011
  Number of {C, E, R, A, U} samples: 92, 23, 30, 67, 853
  Total number of samples:           1065
Year 2012
  Number of {C, E, R, A, U} samples: 111, 27, 37, 46, 858
  Total number of samples:           1079
Year 2013
  Number of {C, E, R, A, U} samples: 103, 31, 30, 71, 825
  Total number of samples:           1060
Year 2014
  Number of {C, E, R, A, U} samples: 38, 17, 10, 24, 353
  Total number of samples:           442
Train and test sets for year 2011
  Number of {C, E, R, A, U} train samples: 97, 39, 17, 87, 922
  Total number of train samples:           1162
  Number of {C, E, R, A, U} test samples:  92, 23, 30, 67, 853
  Total number of test samples:            1065
Train and test sets for year 2011 (merged into 3 classes)
  Number of {+, -, 0} train samples: 39, 114, 1009
  Total number of train samples:     1162
  Number of {+, -, 0} test samples:  23, 122, 920
  Total number of test samples:      1065
Train and test sets for year 2012
  Number of {C, E, R, A, U} train samples: 189, 62, 47, 154, 1775
  Total number of train samples:           2227
  Number of {C, E, R, A, U} test samples:  111, 27, 37, 46, 858
  Total number of test samples:            1079
Train and test sets for year 2012 (merged into 3 classes)
  Number of {+, -, 0} train samples: 62, 236, 1929
  Total number of train samples:     2227
  Number of {+, -, 0} test samples:  27, 148, 904
  Total number of test samples:      1079
Train and test sets for year 2013
  Number of {C, E, R, A, U} train samples: 300, 89, 84, 200, 2633
  Total number of train samples:           3306
  Number of {C, E, R, A, U} test samples:  103, 31, 30, 71, 825
  Total number of test samples:            1060
Train and test sets for year 2013 (merged into 3 classes)
  Number of {+, -, 0} train samples: 89, 384, 2833
  Total number of train samples:     3306
  Number of {+, -, 0} test samples:  31, 133, 896
  Total number of test samples:      1060
Train and test sets for year 2014
  Number of {C, E, R, A, U} train samples: 403, 120, 114, 271, 3458
  Total number of train samples:           4366
  Number of {C, E, R, A, U} test samples:  38, 17, 10, 24, 353
  Total number of test samples:            442
Train and test sets for year 2014 (merged into 3 classes)
  Number of {+, -, 0} train samples: 120, 517, 3729
  Total number of train samples:     4366
  Number of {+, -, 0} test samples:  17, 48, 377
  Total number of test samples:      442
--------------------------------------------------
Step 3: Calculate train and test sets indices
--------------------------------------------------
Number of samples in Xtrainall: 4808
Number of samples in ytrainall: 4808
  Number of samples in trainindiceslist[0]: 1162
  Number of samples in testindiceslist [0]: 1065
  Number of samples in trainindiceslist[1]: 2227
  Number of samples in testindiceslist [1]: 1079
  Number of samples in trainindiceslist[2]: 3306
  Number of samples in testindiceslist [2]: 1060
  Number of samples in trainindiceslist[3]: 4366
  Number of samples in testindiceslist [3]: 442
--------------------------------------------------
Step 4: Run Naive Bayes
--------------------------------------------------
Running Naive Bayes on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.795305164319
  Macro recall    : 0.451003801378
  Macro precision : 0.45707387828
  Macro F1 score  : 0.431202650297
  Confusion matrix:
[[  5   4  14]
 [ 19  31  72]
 [ 69  40 811]]
Running Naive Bayes on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.796107506951
  Macro recall    : 0.461383581221
  Macro precision : 0.49122102022
  Macro F1 score  : 0.455419111598
  Confusion matrix:
[[  5   5  17]
 [ 23  45  80]
 [ 59  36 809]]
Running Naive Bayes on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.77358490566
  Macro recall    : 0.477742996604
  Macro precision : 0.458852287853
  Macro F1 score  : 0.452330239038
  Confusion matrix:
[[  8   5  18]
 [ 18  42  73]
 [ 67  59 770]]
Running Naive Bayes on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.776018099548
  Macro recall    : 0.531844324821
  Macro precision : 0.474656084656
  Macro F1 score  : 0.471511359595
  Confusion matrix:
[[  8   2   7]
 [ 14  13  21]
 [ 34  21 322]]
--------------------------------------------------
Step 5: Find Best Parameters for Decision Tree Classifier using Grid Search
--------------------------------------------------
Running Grid Search on Decision Tree Classifier on classes ('+', '-', '0')
  Best parameters         : {'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 10, 'min_samples_leaf': 0.02, 'min_samples_split': 0.04, 'min_weight_fraction_leaf': 0.0, 'random_state': 689220878, 'max_features': 1, 'max_depth': 3, 'class_weight': 'balanced'}
  Best score              : 0.491347251836
  Best feature importances: [ 0.          0.          0.08757465  0.1371044   0.54643702  0.22888393]
--------------------------------------------------
Step 6: Run Decision Tree Classifier using Best Parameters
--------------------------------------------------
Running Decision Tree Classifier on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.742723004695
  Macro recall    : 0.607923497268
  Macro precision : 0.466333861071
  Macro F1 score  : 0.480019229811
  Confusion matrix:
[[ 11   7   5]
 [ 26  70  26]
 [ 89 121 710]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.705164319249
  Macro recall    : 0.564813494892
  Macro precision : 0.45980787411
  Macro F1 score  : 0.439211157467
  Confusion matrix:
[[ 13   5   5]
 [ 59  46  17]
 [148  80 692]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2011 and classes ('+', '-', '0')
  Accuracy        : 0.72676056338
  Macro recall    : 0.521454027085
  Macro precision : 0.444953503492
  Macro F1 score  : 0.440223099758
  Confusion matrix:
[[  8  10   5]
 [ 42  54  26]
 [106 102 712]]
Running Decision Tree Classifier on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.759036144578
  Macro recall    : 0.605137955064
  Macro precision : 0.487054438087
  Macro F1 score  : 0.511878168859
  Confusion matrix:
[[ 11   9   7]
 [ 22  91  35]
 [ 49 138 717]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.754402224282
  Macro recall    : 0.614063547323
  Macro precision : 0.48639040995
  Macro F1 score  : 0.507358889281
  Confusion matrix:
[[ 13   7   7]
 [ 29  84  35]
 [ 63 124 717]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2012 and classes ('+', '-', '0')
  Accuracy        : 0.746987951807
  Macro recall    : 0.545578395505
  Macro precision : 0.469347784571
  Macro F1 score  : 0.477799783156
  Confusion matrix:
[[  8  12   7]
 [ 32  81  35]
 [ 74 113 717]]
Running Decision Tree Classifier on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.73679245283
  Macro recall    : 0.550156894252
  Macro precision : 0.457349950601
  Macro F1 score  : 0.47537979623
  Confusion matrix:
[[ 10  15   6]
 [ 19  73  41]
 [ 54 144 698]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.742452830189
  Macro recall    : 0.540455220713
  Macro precision : 0.463939690381
  Macro F1 score  : 0.479721842599
  Confusion matrix:
[[  7  18   6]
 [ 10  82  41]
 [ 30 168 698]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2013 and classes ('+', '-', '0')
  Accuracy        : 0.710377358491
  Macro recall    : 0.518107264128
  Macro precision : 0.44491963229
  Macro F1 score  : 0.445405098584
  Confusion matrix:
[[ 11  11   9]
 [ 34  58  41]
 [105 107 684]]
Running Decision Tree Classifier on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.753393665158
  Macro recall    : 0.594640132799
  Macro precision : 0.481583648295
  Macro F1 score  : 0.506815548062
  Confusion matrix:
[[  6   7   4]
 [  6  31  11]
 [ 24  57 296]]
Running Decision Tree Classifier (with SMOTE) on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.744343891403
  Macro recall    : 0.566862355022
  Macro precision : 0.467828587007
  Macro F1 score  : 0.485889304494
  Confusion matrix:
[[  6   7   4]
 [ 10  27  11]
 [ 33  48 296]]
Running Decision Tree Classifier (with TOMEK) on train and test sets for year 2014 and classes ('+', '-', '0')
  Accuracy        : 0.744343891403
  Macro recall    : 0.566862355022
  Macro precision : 0.467356564522
  Macro F1 score  : 0.485764747117
  Confusion matrix:
[[  6   7   4]
 [ 10  27  11]
 [ 32  49 296]]
--------------------------------------------------
Step 7: Calculate f-statistic
--------------------------------------------------
Calculating f-statistic for Decision Tree Classifier (No resampling vs SMOTE oversampling vs TOMEK undersampling)
  F-statistic: 1.74787422681, P-Value: 0.228381572716
--------------------------------------------------
Step 8: Calculate t-statistic
--------------------------------------------------
Calculating t-statistic for Naive Bayes and Decision Tree Classifier (No resampling)
  T-statistic: -3.29583989722, P-Value: 0.0167808536731
--------------------------------------------------
Step 9: Fit Decision Tree to Whole Dataset and Export to File
--------------------------------------------------
Running Decision Tree Classifier on whole dataset
  Decision Tree Exported to File:gdp_tree_2017-12-21_23-42-35.png
